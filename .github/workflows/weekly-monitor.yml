# This workflow monitors a weekly run of the elevate CI.
# It runs weekly at 3:00 PM UTC (9:00 AM CST, 10:00 AM CDT) to check the status of tests
# that were triggered by weekly-testing.yml at 9:00 AM UTC (3:00 AM CST, 4:00 AM CDT).
#
# IMPORTANT: When running on schedule, tests that are still "in progress" after 5+ hours
# are treated as failures/timeouts since this indicates a problem with the test run.
#
# The workflow:
# 1. Checks the most recent testsuite.yml workflow run
# 2. Reports detailed status
# 3. Creates a summary report and fails if any tests failed
#
# Manual triggering is supported with a configurable lookback period.

name: Monitor Weekly Test Results

on:
  schedule:
    - cron: '0 3 * * 0'    # 03:00 UTC (9 am CST, 10 am CDT)
  workflow_dispatch:    # Allow manual triggering for testing
    inputs:
      hours_back:
        description: 'Hours to look back for workflow runs'
        required: false
        default: '24'
        type: string

env:
  SANDBOX_WORKFLOW_FILE: testsuite.yml

jobs:
  monitor-weekly-results:
    name: Check weekly Elevate CI results
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
    env:
      #       Get the thing from Todd unless he adds it or just reuse the ulc one
      SLACK_WEBHOOK_FOR_ELEVATE: ${{ secrets.SLACK_WEBHOOK_FOR_ELEVATE }}

    steps:
      - name: Check workflow runs
        id: check-runs
        run: |
          TABLE_ROWS=""
          OVERALL_STATUS="success"
          HOURS_BACK="${{ github.event.inputs.hours_back || '24' }}"

          echo "Looking back $HOURS_BACK hours for workflow runs"

          # Get the most recent workflow run
          # Look for runs from the specified hours back to catch the weekly run
          SINCE=$(date -d "$HOURS_BACK hours ago" --iso-8601=seconds)

          WORKFLOW_RUNS=$(curl -s \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ github.token }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            "${{ github.api_url }}/repos/${{ github.repository }}/actions/workflows/${{ env.SANDBOX_WORKFLOW_FILE }}/runs?branch=main&created=>=$SINCE&per_page=1")

          # Check if we got any runs
          RUN_COUNT=$(echo "$WORKFLOW_RUNS" | jq '.total_count')

          if [ "$RUN_COUNT" -eq 0 ]; then
            echo "ðŸ”´ FAILED: No recent runs found for branch main"
            TABLE_ROWS="${TABLE_ROWS}| main | ðŸ”´ **FAILED** | No recent runs found | - | - | - |"$'\n'
            OVERALL_STATUS="failure"
          else
            # Get the most recent run details
            RUN_STATUS=$(echo "$WORKFLOW_RUNS" | jq -r '.workflow_runs[0].conclusion')
            RUN_URL=$(echo "$WORKFLOW_RUNS" | jq -r '.workflow_runs[0].html_url')
            RUN_ID=$(echo "$WORKFLOW_RUNS" | jq -r '.workflow_runs[0].id')
            CREATED_AT=$(echo "$WORKFLOW_RUNS" | jq -r '.workflow_runs[0].created_at')
            COMMIT_SHA=$(echo "$WORKFLOW_RUNS" | jq -r '.workflow_runs[0].head_sha')
            SHORT_SHA=${COMMIT_SHA:0:12}
            COMMIT_LINK="[\`$SHORT_SHA\`](${{ github.server_url }}/${{ github.repository }}/commit/$COMMIT_SHA)"

            echo "Run ID: $RUN_ID"
            echo "Status: $RUN_STATUS"
            echo "Created: $CREATED_AT"
            echo "URL: $RUN_URL"

            # Get all jobs for this workflow run
            JOBS=$(curl -s \
              -H "Accept: application/vnd.github+json" \
              -H "Authorization: Bearer ${{ github.token }}" \
              -H "X-GitHub-Api-Version: 2022-11-28" \
              "${{ github.api_url }}/repos/${{ github.repository }}/actions/runs/$RUN_ID/jobs")

            # Get the results of the jobs
            # jq -r --arg suffix "terraform_openstack_destroy" '.jobs[] | select((.name | endswith($suffix)) or (.name == "testsuite")) | select(.conclusion == "success") | .name'
            FAILED_JOBS=$(echo "$JOBS" | jq -r --arg suffix "terraform_openstack_destroy" '.jobs[] | select((.name | endswith($suffix)) or (.name == "testsuite")) | select(.conclusion == "failure") | .name')
            PENDING_JOBS=$(echo "$JOBS" | jq -r --arg suffix "terraform_openstack_destroy" '.jobs[] | select((.name | endswith($suffix)) or (.name == "testsuite")) | select(.conclusion == null or .conclusion == "") | .name')
            TOTAL_SMOKER_JOBS=$(echo "$JOBS" | jq -r --arg suffix "terraform_openstack_destroy" '.jobs[] | select((.name | endswith($suffix)) or (.name == "testsuite")) | .name' | wc -l)
            FAILED_COUNT=$(echo "$FAILED_JOBS" | grep -c . || echo "0")
            PENDING_COUNT=$(echo "$PENDING_JOBS" | grep -c . || echo "0")

            if [ "$PENDING_COUNT" -gt 0 ]; then
              echo "ðŸ”´ TIMEOUT: Branch main: $PENDING_COUNT/$TOTAL_SMOKER_JOBS jobs still running after 5+ hours"
              TABLE_ROWS="${TABLE_ROWS}| main | ðŸ”´ **TIMEOUT** | $PENDING_COUNT/$TOTAL_SMOKER_JOBS jobs still running after 5+ hours | [View Run]($RUN_URL) | $COMMIT_LINK | $(TZ='America/Chicago' date -d "$CREATED_AT" '+%Y-%m-%d %H:%M %Z') |"$'\n'
              OVERALL_STATUS="failure"
            elif [ "$FAILED_COUNT" -gt 0 ]; then
              echo "ðŸ”´ FAILED: Branch main: $FAILED_COUNT/$TOTAL_SMOKER_JOBS jobs failed"
              # Extract platform info from failed job names for better reporting
              FAILED_PLATFORMS=$(echo "$FAILED_JOBS" | cut -d '/' -f1)
              TABLE_ROWS="${TABLE_ROWS}| main | ðŸ”´ **FAILED** | Failed: $FAILED_PLATFORMS | [View Run]($RUN_URL) | $COMMIT_LINK | $(TZ='America/Chicago' date -d "$CREATED_AT" '+%Y-%m-%d %H:%M %Z') |"$'\n'
              OVERALL_STATUS="failure"
            elif [ "$TOTAL_SMOKER_JOBS" -gt 0 ]; then
              echo "ðŸŸ¢ SUCCESS: Branch main: All $TOTAL_SMOKER_JOBS jobs passed"
              TABLE_ROWS="${TABLE_ROWS}| main | ðŸŸ¢ **SUCCESS** | All $TOTAL_SMOKER_JOBS jobs passed | [View Run]($RUN_URL) | $COMMIT_LINK | $(TZ='America/Chicago' date -d "$CREATED_AT" '+%Y-%m-%d %H:%M %Z') |"$'\n'
            else
              echo "âšª UNKNOWN: Branch main: No smoker jobs found"
              TABLE_ROWS="${TABLE_ROWS}| main | âšª **UNKNOWN** | No jobs found | [View Run]($RUN_URL) | $COMMIT_LINK | $(TZ='America/Chicago' date -d "$CREATED_AT" '+%Y-%m-%d %H:%M %Z') |"$'\n'
              OVERALL_STATUS="failure"
            fi
          fi

          # Save table rows for the summary
          echo "table_rows<<EOF" >> $GITHUB_OUTPUT
          echo "$TABLE_ROWS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "overall_status=$OVERALL_STATUS" >> $GITHUB_OUTPUT

      - name: Create summary
        run: |
          cat << 'EOF' >> $GITHUB_STEP_SUMMARY
          # Nightly Test Results Summary

          **Overall Status**: ${{ steps.check-runs.outputs.overall_status == 'success' && 'ðŸŸ¢ **All tests passing**' || 'ðŸ”´ **Some tests failed**' }}

          ## Branch Results

          | Branch | Status | Details | Run Link | Commit | Houston Time |
          |--------|--------|---------|----------|--------|--------------|
          ${{ steps.check-runs.outputs.table_rows }}

          ---

          *Report generated at $(date -u '+%Y-%m-%d %H:%M:%S UTC')*

          **Legend:**
          - ðŸŸ¢ **SUCCESS**: All matrix jobs passed
          - ðŸ”´ **FAILED**: One or more matrix jobs failed (shows which platforms)
          - ðŸ”´ **TIMEOUT**: Tests still running after 5+ hours (scheduled runs only)
          - âšª **UNKNOWN**: No recent runs found or unexpected status
          EOF

      - name: Post table to Slack
        if: ${{ env.SLACK_WEBHOOK_FOR_ELEVATE != '' }}
        run: |
          # Build Slack-friendly mrkdwn from the GitHub table rows
          ROWS=$(cat << 'EOT'
          ${{ steps.check-runs.outputs.table_rows }}
          EOT
          )

          # Transform pipe-separated rows into bullet lines; link Branch and "View Run" only
          LINES=$(awk -F '|' '
            function trim(s){ sub(/^ +/,"",s); sub(/ +$/,"",s); return s }
            NF>1 {
              b=trim($2); s=trim($3); d=trim($4); r=trim($5); c=trim($6); t=trim($7);
              # Extract URL from markdown link in r (Run Link)
              run_url=r;
              if (match(r, /\(([^)]+)\)/)) { run_url=substr(r, RSTART+1, RLENGTH-2) }
              # Link Branch to the run; keep Details as plain text; keep an explicit View Run link; drop timestamp to avoid wrapping
              print "â€¢ <" run_url "|*" b "*> â€” " s " â€” " d " â€” <" run_url "|View Run> â€” " c
            }
          ' <<< "$ROWS")

          # Convert [text](url) -> <url|text> and **bold** -> *bold*
          LINES=$(printf "%s\n" "$LINES" | sed -E 's/\[([^]]+)\]\(([^)]+)\)/<\2|\1>/g' | sed -E 's/\*\*([^*]+)\*\*/*\1*/g')

          # Build Slack blocks payload
          PAYLOAD=$(jq -n \
            --arg status "${{ steps.check-runs.outputs.overall_status }}" \
            --arg text "$LINES" \
            '{
              blocks: [
                { type: "header", text: { type: "plain_text", text: ("Nightly Test Results: " + (if $status == "success" then "All tests passing ðŸŸ¢" else "Issues detected ðŸ”´" end)), emoji: true } },
                { type: "divider" },
                { type: "section", text: { type: "mrkdwn", text: $text } }
              ]
            }')

          curl -sS -X POST -H 'Content-type: application/json' \
            --data "$PAYLOAD" \
            "$SLACK_WEBHOOK_FOR_ELEVATE"

      - name: Send notification on failure
        if: steps.check-runs.outputs.overall_status != 'success'
        run: |
          echo "::warning::One or more nightly test runs failed or are missing"
          echo "Check the summary above for details on which branches failed"

          # Create a more detailed error message
          cat << 'EOF' >> $GITHUB_STEP_SUMMARY

          ## Action Required

          Some nightly tests have failed, timed out, or are missing. Please:

          1. Check the individual workflow runs linked above
          2. Investigate any failures or timeouts in the failing branches
          3. For TIMEOUT status: Check if tests are stuck or infrastructure issues exist
          4. Consider re-running failed tests if they appear to be flaky
          5. Update relevant teams if there are persistent issues

          EOF

      - name: Fail if any tests failed
        if: steps.check-runs.outputs.overall_status != 'success'
        run: |
          echo "::error::One or more nightly test runs failed or are missing"
          exit 1
